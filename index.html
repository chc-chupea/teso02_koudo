<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>手相ミライ診断 - 全部入りテンプレ</title>
<style>
  body { font-family: "Yu Gothic", sans-serif; background:#fff0f6; color:#5a3e36; text-align:center; margin:0; padding:1rem;}
  #video, #outputCanvas, #edgeCanvas {
    width: 320px; height: 240px; border-radius: 12px; background:#eee; margin:0.5rem auto; display:block;
  }
  #diagnosisResult {
    margin-top:1rem; padding:1rem; background:#ffe6f0; border-radius:1rem; max-width:320px; margin-left:auto; margin-right:auto; text-align:left;
  }
  button {
    padding:0.6rem 1rem; font-size:1rem; border-radius:0.5rem; border:none; background:#f48abf; color:#fff; cursor:pointer;
  }
  button:disabled {
    background:#f9c0d6; cursor:not-allowed;
  }
</style>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>
<script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
</head>
<body>

<h1>手相ミライ診断（全部入りテンプレ）</h1>

<video id="video" autoplay playsinline muted></video>
<canvas id="outputCanvas" width="320" height="240"></canvas>
<canvas id="edgeCanvas" width="320" height="240"></canvas>

<button id="startBtn">カメラ起動</button>
<button id="captureBtn" disabled>診断用キャプチャ</button>

<div id="diagnosisResult"></div>

<script>
  let video = document.getElementById("video");
  let outputCanvas = document.getElementById("outputCanvas");
  let edgeCanvas = document.getElementById("edgeCanvas");
  let ctx = outputCanvas.getContext("2d");
  let edgeCtx = edgeCanvas.getContext("2d");

  let stream = null;
  let hands = null;
  let landmarks = null;
  let opencvReady = false;

  const diagnosisResult = document.getElementById("diagnosisResult");
  const startBtn = document.getElementById("startBtn");
  const captureBtn = document.getElementById("captureBtn");

  // 診断コメントのテンプレート（ざっくり例）
  const lineComments = {
    life: ["生命線はっきり長い。健康でタフ。", "生命線やや短め。注意必要。"],
    emotion: ["感情線しっかり。情熱的。", "感情線薄め。冷静派かも。"],
    brain: ["頭脳線伸びて多才。", "頭脳線短めで集中力あり。"],
    fate: ["運命線強くて転機多い。", "運命線薄く変化少なめ。"],
    marriage: ["結婚線2本で揺れる時期。", "結婚線1本で安定期。"]
  };

  // OpenCV.js準備待ち
  function onOpenCvReady() {
    console.log("OpenCV.js is ready");
    opencvReady = true;
    captureBtn.disabled = false;
  }
  // OpenCV.jsロード完了を監視
  if (typeof cv === "undefined") {
    document.addEventListener('opencvready', onOpenCvReady);
  } else {
    onOpenCvReady();
  }

  // MediaPipe Hands初期化
  function initHands() {
    hands = new Hands({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
    });
    hands.setOptions({
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.7,
      minTrackingConfidence: 0.7
    });
    hands.onResults(onHandsResults);
  }

  // カメラ起動
  async function startCamera() {
    stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:"environment"}, audio:false});
    video.srcObject = stream;
    await video.play();
    captureBtn.disabled = false;
  }

  // MediaPipeで手検出
  async function detectHands() {
    if (!hands) initHands();
    await hands.send({image: video});
  }

  // 手検出結果で描画とランドマーク保存
  function onHandsResults(results) {
    ctx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
    ctx.drawImage(results.image, 0, 0, outputCanvas.width, outputCanvas.height);
    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
      landmarks = results.multiHandLandmarks[0];
      drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {color:"#00FF00", lineWidth:3});
      drawLandmarks(ctx, landmarks, {color:"#FF0000", lineWidth:2});
    } else {
      landmarks = null;
    }
  }

  // 線の位置判定（超ざっくり座標例）で擬似分類
  function classifyLines(edgeMat) {
    // 仮：手の領域中央から下あたりで長めの曲線検出→生命線など判定
    // ここは要調整。今はランダムにコメントを返す形に
    let result = {
      life: lineComments.life[Math.floor(Math.random()*lineComments.life.length)],
      emotion: lineComments.emotion[Math.floor(Math.random()*lineComments.emotion.length)],
      brain: lineComments.brain[Math.floor(Math.random()*lineComments.brain.length)],
      fate: lineComments.fate[Math.floor(Math.random()*lineComments.fate.length)],
      marriage: lineComments.marriage[Math.floor(Math.random()*lineComments.marriage.length)]
    };
    return result;
  }

  // キャプチャ＆エッジ抽出＆判定
  function captureAndAnalyze() {
    if (!opencvReady) {
      alert("OpenCV.jsの読み込みがまだ完了していません。");
      return;
    }
    if (!landmarks) {
      alert("手が検出されていません。カメラ映像を調整してください。");
      return;
    }
    // outputCanvasの画像をOpenCVに読み込み
    let src = cv.imread(outputCanvas);
    let gray = new cv.Mat();
    let edges = new cv.Mat();

    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
    cv.GaussianBlur(gray, gray, new cv.Size(5,5), 0);
    cv.Canny(gray, edges, 50, 150);

    cv.imshow(edgeCanvas, edges);

    // 線分類（擬似）
    let classification = classifyLines(edges);

    // 診断結果表示
    diagnosisResult.innerHTML = `
      <h3>🖐 あなたの手相結果</h3>
      <ul>
        <li>・生命線：${classification.life}</li>
        <li>・感情線：${classification.emotion}</li>
        <li>・頭脳線：${classification.brain}</li>
        <li>・運命線：${classification.fate}</li>
        <li>・結婚線：${classification.marriage}</li>
      </ul>
    `;

    // 後片付け
    src.delete(); gray.delete(); edges.delete();
  }

  startBtn.addEventListener("click", async () => {
    startBtn.disabled = true;
    await startCamera();
    // 連続検出
    const detectLoop = async () => {
      await detectHands();
      requestAnimationFrame(detectLoop);
    };
    detectLoop();
  });

  captureBtn.addEventListener("click", captureAndAnalyze);
</script>

</body>
</html>